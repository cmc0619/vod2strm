# vod2strm Performance Analysis Report

**Date:** 2025-12-21
**Codebase Version:** 0.0.13
**Analysis Scope:** Database queries, file I/O, threading, memory usage

---

## Executive Summary

This analysis identified **11 performance issues** across the vod2strm plugin codebase, ranging from critical N+1 query patterns to moderate memory inefficiencies. The most impactful issues affect series generation and cleanup operations at scale.

**Priority Breakdown:**
- ðŸ”´ **Critical (1):** N+1 queries that multiply with dataset size
- ðŸŸ¡ **Moderate (6):** Memory inefficiencies and potential N+1 scenarios
- ðŸŸ¢ **Low (4):** Minor optimizations with limited impact

---

## Critical Issues (Immediate Attention Required)

### ðŸ”´ 1. N+1 Query in Series Refresh - `plugin.py:1302-1304`

**Location:** `_maybe_internal_refresh_series()`

**Problem:**
```python
relation = series.m3u_relations.select_related('m3u_account').filter(
    m3u_account__is_active=True
).order_by('-m3u_account__priority', 'id').first()
```

Called inside series iteration loop (line 1414), but `series.m3u_relations` is **not prefetched**. This triggers one additional query per series.

**Impact:** For 10,000 series with 0 episodes â†’ **10,000 extra queries**

**Solution:**
```python
# In _generate_series(), add prefetch:
series_qs = _eligible_series_queryset().annotate(
    episode_count=Count('episodes', distinct=True)
).prefetch_related(
    Prefetch('m3u_relations',
             queryset=M3USeriesRelation.objects.filter(
                 m3u_account__is_active=True
             ).select_related('m3u_account').order_by('-m3u_account__priority', 'id'),
             to_attr='active_series_relations')
).only(...)
```

---

## Moderate Issues (Performance Impact at Scale)

### ðŸŸ¡ 2. Memory Overload in Cleanup - `plugin.py:923-927, 954`

**Location:** `_cleanup()`

**Problem:**
```python
# Loads ALL UUIDs into Python memory
movie_uuids = set(str(u) for u in _eligible_movie_queryset().values_list("uuid", flat=True))
episode_uuids = set(str(u) for u in Episode.objects.filter(...).values_list("uuid", flat=True))

# Loads ALL file paths into memory
strm_files = list(root.rglob("*.strm"))
```

**Impact:**
- 100K movies Ã— 36 bytes (UUID string) = **3.6 MB**
- 1M episodes Ã— 36 bytes = **36 MB**
- 1M .strm file paths Ã— ~100 bytes = **100 MB**
- **Total: ~140 MB** for large library (acceptable, but inefficient)

**Solution:** Process in chunks using iterators:
```python
# Option 1: Generator-based approach
def cleanup_generator():
    for strm_path in root.rglob("*.strm"):
        yield check_and_cleanup(strm_path)

# Option 2: Batch processing (check 10K files at a time)
batch_size = 10000
movie_uuids_batch = set()
# Fetch in chunks...
```

---

### ðŸŸ¡ 3. Inefficient Fallback Queries - `plugin.py:1169-1170, 1480-1481`

**Location:** `_generate_movies()`, `_generate_series()`

**Problem:**
```python
relations = getattr(m, 'active_relations', [])
if not relations:
    # Falls back to individual query if prefetch fails
    relations = list(active_movie_relations.filter(movie_id=m.id))
```

**Impact:** If prefetch breaks â†’ **N queries** (one per movie/episode). Silent performance degradation.

**Solution:** Add logging and fail fast:
```python
if not relations:
    LOGGER.warning("Prefetch failed for movie id=%s, falling back to individual query", m.id)
    relations = list(active_movie_relations.filter(movie_id=m.id))
    # Consider raising an alert if this happens frequently
```

---

### ðŸŸ¡ 4. Redundant Episode Count Query - `plugin.py:1445-1452`

**Location:** `_generate_series()`

**Problem:**
```python
total_before_distinct = eps_query.count()  # â† Extra COUNT(*) query
eps = list(eps_query.distinct().prefetch_related(...))
total_after_distinct = len(eps)

if total_before_distinct > total_after_distinct:
    LOGGER.warning("Duplicate relations detected...")
```

**Impact:** One extra `COUNT(*)` query **per series** (only to detect issue #569). For 10,000 series = **10,000 extra queries**.

**Solution:** Only run check in debug mode:
```python
if LOGGER.level <= logging.DEBUG:
    total_before_distinct = eps_query.count()
    # ... duplicate detection logic
```

---

### ðŸŸ¡ 5. File System Stats Without Streaming - `plugin.py:1692-1694`

**Location:** `_stats_only()`

**Problem:**
```python
movies_strm = len(list((root / "Movies").rglob("*.strm")))
tv_strm = len(list((root / "TV").rglob("*.strm")))
nfos = len(list(root.rglob("*.nfo")))
```

**Impact:** Loads all file paths into memory. For 500K files Ã— 100 bytes = **50 MB** wasted.

**Solution:** Use generator expression:
```python
movies_strm = sum(1 for _ in (root / "Movies").rglob("*.strm")) if (root / "Movies").exists() else 0
```

---

### ðŸŸ¡ 6. Settings Loaded Multiple Times - `plugin.py:146-152, 179-185`

**Location:** `_eligible_movie_queryset()`, `_eligible_series_queryset()`

**Problem:**
```python
# Both functions independently load settings from DB
from apps.plugins.models import PluginConfig
config = PluginConfig.objects.filter(key="vod2strm").first()
settings = config.settings if config else {}
```

Called multiple times during generation â†’ **redundant DB queries**.

**Solution:** Pass settings as parameter from caller:
```python
def _eligible_movie_queryset(filter_movie_ids_str: Optional[str] = None):
    # Accept pre-loaded settings instead of querying
```

---

### ðŸŸ¡ 7. Per-Episode Validation Query - `plugin.py:794-795`

**Location:** `_make_episode_strm_and_nfo()`

**Problem:**
```python
# Workaround for Dispatcharr bug #556
episode_exists = Episode.objects.filter(id=episode.id).exists()
```

**Impact:** One `EXISTS()` query **per episode**. For 100K episodes = **100K queries**.

**Why it exists:** Episodes can disappear mid-generation due to sync conflicts (Dispatcharr bug #556).

**Solution:** Batch validation every N episodes:
```python
# Validate in batches of 100
episode_ids_to_check = [batch of 100 episode IDs]
valid_ids = set(Episode.objects.filter(id__in=episode_ids_to_check).values_list('id', flat=True))
```

---

## Low Priority Issues (Minor Optimizations)

### ðŸŸ¢ 8. Tree Comparison File Counting - `plugin.py:720-731`

**Location:** `_compare_tree_quick()`

**Problem:**
```python
strm_count = len(list(series_root.rglob("*.strm")))
nfo_eps = len(list(series_root.rglob("S??E??.nfo")))
```

**Impact:** Minor - only called once per series to check if already complete.

**Solution:** Use generator (same as #5).

---

### ðŸŸ¢ 9. Repeated Episode Count After Refresh - `plugin.py:1417`

**Location:** `_generate_series()`

**Problem:**
```python
expected = _series_expected_count(s.id)  # â† Extra COUNT query
```

Called after internal refresh completes. Could reuse annotation.

**Solution:**
```python
# Refresh should return episode count, avoiding extra query
episode_count = _maybe_internal_refresh_series(s)
expected = episode_count if episode_count else s.episode_count
```

---

### ðŸŸ¢ 10. ThreadPoolExecutor Recreated Per Batch - `plugin.py:1200-1201, 1511-1512`

**Location:** `_generate_movies()`, `_generate_series()`

**Problem:**
```python
for i in range(0, len(all_movies), batch_size):
    batch = all_movies[i:i + batch_size]
    current_workers = throttle.get_workers()
    with ThreadPoolExecutor(max_workers=max(1, current_workers)) as ex:
        list(ex.map(job, batch))
```

Thread pool creation has overhead (~50-100ms per batch).

**Why it's done this way:** Adaptive throttling changes worker count dynamically. Reusing pool would require manual thread management.

**Verdict:** Current approach is acceptable trade-off for code simplicity.

---

### ðŸŸ¢ 11. Raw SQL in Stats Without Index Hints - `plugin.py:1547-1608`

**Location:** `_db_stats()`

**Problem:** Multiple JOIN queries without index hints:
```sql
SELECT ma.name, ma.id, COUNT(DISTINCT m.id) as count
FROM vod_movie m
INNER JOIN vod_m3umovierelation mr ON m.id = mr.movie_id
INNER JOIN m3u_m3uaccount ma ON mr.m3u_account_id = ma.id
GROUP BY ma.name, ma.id
```

**Impact:** Only runs in stats action (user-initiated), so minimal.

**Solution:** Not needed - PostgreSQL query planner should handle this.

---

## Performance Best Practices Already Implemented âœ…

The codebase demonstrates several **excellent** performance patterns:

1. **âœ… Prefetching Relations** - Lines 1145-1147, 1446-1451
   ```python
   qs = _eligible_movie_queryset().prefetch_related(
       Prefetch('m3u_relations', queryset=active_movie_relations, to_attr='active_relations')
   )
   ```

2. **âœ… Manifest Caching** - Lines 532-580
   - Avoids redundant disk writes by tracking file state
   - Includes URL in cache to detect changes

3. **âœ… Adaptive Throttling** - Lines 362-441
   - Protects NAS from I/O overload
   - Dynamically adjusts concurrency based on latency

4. **âœ… Atomic File Writes** - Lines 329-358
   - Write to temp file, then rename (prevents corruption)

5. **âœ… File-Level Locking** - Lines 316-323, 346-354
   - Uses `fcntl.flock()` to prevent concurrent manifest corruption

6. **âœ… Iterator for Large Querysets** - Line 1406
   ```python
   for s in series_qs.iterator(chunk_size=200):
   ```

7. **âœ… Batch Processing** - Lines 1159-1204
   - Processes movies in batches of 100 for adaptive concurrency adjustments

8. **âœ… `.only()` to Limit Fields** - Lines 1147-1149, 1448-1451
   - Reduces data transfer from database

---

## Recommendations by Priority

### Immediate (Next Release)

1. **Fix N+1 in series refresh** (#1) - Add prefetch for `m3u_relations`
2. **Conditional duplicate detection** (#4) - Only run `COUNT()` in debug mode
3. **Add prefetch failure logging** (#3) - Detect silent performance degradation

### Medium-Term (Future Release)

4. **Batch episode validation** (#7) - Reduce queries from 100K â†’ 1K
5. **Stream file stats** (#5, #8) - Use generators instead of `list()`
6. **Chunk cleanup operations** (#2) - Process files in batches

### Low Priority (Nice to Have)

7. **Cache settings** (#6) - Avoid redundant PluginConfig queries
8. **Return episode count from refresh** (#9) - Eliminate redundant COUNT

---

## Scalability Analysis

**Current Performance:**
- âœ… **Movies:** Scales well to 100K+ (good prefetching)
- âš ï¸ **Series:** Acceptable to 10K, degrades beyond 50K (N+1 on refresh)
- âš ï¸ **Cleanup:** Memory usage grows linearly, acceptable to 1M files

**After Fixes:**
- âœ… **Series:** Should handle 100K+ series efficiently
- âœ… **Cleanup:** Can process multi-million file libraries

---

## Testing Recommendations

To validate fixes:

1. **Profile with Django Debug Toolbar:**
   ```python
   # Add to settings.py for profiling
   INSTALLED_APPS += ['debug_toolbar']
   # Check query count per operation
   ```

2. **Benchmark large datasets:**
   ```python
   # Create test data: 10K series, 100K episodes
   # Measure: total queries, execution time, peak memory
   ```

3. **Monitor manifest lock contention:**
   ```python
   # Add timing to _MANIFEST_LOCK acquisition
   # Alert if wait time > 100ms
   ```

---

## Conclusion

The vod2strm plugin demonstrates **strong performance fundamentals** (prefetching, caching, adaptive throttling), but suffers from a few **high-impact N+1 patterns** that degrade performance at scale.

**Quick wins:**
- Fix series refresh N+1 (#1) â†’ **~10X speedup** for series with 0 episodes
- Conditional duplicate detection (#4) â†’ **50% fewer queries** during series generation
- Batch episode validation (#7) â†’ **~100X reduction** in validation queries

**Estimated improvement:** After implementing the top 3 fixes, expect **2-5X performance improvement** for large series libraries (10K+ series).
